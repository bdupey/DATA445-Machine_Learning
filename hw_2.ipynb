{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical Questions\n",
    "\n",
    "1. (d) Bootstrapping\n",
    "2. (b) low bias and high variance\n",
    "3. (c) high bias and low variance\n",
    "4. Regularization is a technique that is used to improve the way a statistical model is fitted to a set of data. It is useful because it can prevent overfitting of the model and make more accurate predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (a) (4 points) Using the pandas library, read the csv data file and create a data-frame called heart.\n",
    "heart=pd.read_csv('framingham.csv')\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) (3 points) Remove observations with missing values.\n",
    "heart=heart.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average f1 score for model 1 is  0.3491375244169693 \n",
      "The average f1 score for model 2 is  0.3345260800021302\n"
     ]
    }
   ],
   "source": [
    "# (c) (25 points) Perform a 5-folds cross validation with the goal of measuring the performance,\n",
    "#     in terms of F1-score, of two competing models:\n",
    "    # • Using age, currentSmoker, totChol, sysBP, diaBP, BMI, heartRate, and glucose as\n",
    "    #   the predictor variables, and TenYearCHD as the target variable build a logistic regression\n",
    "    #   model under the 5-folds cross validation framework. Compute and store the F1-score\n",
    "    #   for each iteration.\n",
    "    # • Using age, currentSmoker, totChol, BMI, heartRate, and glucose as the predictor\n",
    "    #   variables, and TenYearCHD as the target variable build a logistic regression model under the 5-folds cross validation framework. Compute and store the F1-score for each\n",
    "    #   iteration.\n",
    "        # Use 25% as threshold to change the likelihoods to labels. Make sure to scale the input\n",
    "        # variables of both models to 0-1 range (see MinMaxScaler) before you run the 5-fold cross\n",
    "        # validation framework. Also, you can use the f1 score function to compute the F1-score.\n",
    "\n",
    "# Train test split\n",
    "X=heart[['age', 'currentSmoker', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']]\n",
    "Y=heart['TenYearCHD']\n",
    "\n",
    "# Creating scaler\n",
    "scaler=MinMaxScaler()\n",
    "\n",
    "# Defining lists to store the MSE\n",
    "model_1_f1_scores,model_2_f1_scores=[],[]\n",
    "\n",
    "kfold=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, val_idx in kfold.split(X):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "    \n",
    "    ###########\n",
    "    # Model 1 #\n",
    "    ###########\n",
    "    \n",
    "    # Scaling the training data\n",
    "    X_train_scaled_1=scaler.fit_transform(X_train)\n",
    "    # Building the model\n",
    "    logit_md_1=LogisticRegression().fit(X_train_scaled_1, Y_train)\n",
    "    # Scaling the testing data\n",
    "    X_test_scaled_1=scaler.transform(X_test)\n",
    "    # Predicting on the testing data\n",
    "    logit_pred_1=logit_md_1.predict_proba(X_test_scaled_1)[:, 1]\n",
    "    # Changing likelihood to labels\n",
    "    logit_label_1 = np.where(logit_pred_1<0.25,0,1)\n",
    "    # Calculating the f1 score\n",
    "    f1_1=f1_score(Y_test, logit_label_1)\n",
    "    # Appending f1 score to list\n",
    "    model_1_f1_scores.append(f1_1)\n",
    "\n",
    "    ###########\n",
    "    # Model 2 #\n",
    "    ###########\n",
    "\n",
    "    # Dropping columns from training data for model 2\n",
    "    X_train_2=X_train.drop(columns=['sysBP', 'diaBP'], axis=1)\n",
    "    # Scaling the training data\n",
    "    X_train_scaled_2=scaler.fit_transform(X_train_2)\n",
    "    # Building the model\n",
    "    logit_md_2=LogisticRegression().fit(X_train_scaled_2, Y_train)\n",
    "    # Dropping columns from testing data for model 2\n",
    "    X_test_2=X_test.drop(columns=['sysBP', 'diaBP'], axis=1)   \n",
    "    # Scaling the testing data\n",
    "    X_test_scaled_2=scaler.transform(X_test_2)\n",
    "    # Predicting on the testing data\n",
    "    logit_pred_2=logit_md_2.predict_proba(X_test_scaled_2)[:, 1]\n",
    "    # Changing likelihood to labels\n",
    "    logit_label_2 = np.where(logit_pred_2<0.25,0,1)\n",
    "    # Calculating the f1 score\n",
    "    f1_2=f1_score(Y_test, logit_label_2)\n",
    "    # Appending f1 score to list\n",
    "    model_2_f1_scores.append(f1_2)\n",
    "\n",
    "\n",
    "# (d) (4 points) Report the average F1-score of each of the models. What model would you use\n",
    "# to predict TenYearCHD? Explain\n",
    "\n",
    "def Average(list):\n",
    "    avg=np.average(list)\n",
    "    return(avg)\n",
    "\n",
    "model_1_avg_f1_score=Average(model_1_f1_scores)\n",
    "model_2_avg_f1_score=Average(model_2_f1_scores)\n",
    "\n",
    "print(\"The average f1 score for model 1 is \", model_1_avg_f1_score, \"\\nThe average f1 score for model 2 is \", model_2_avg_f1_score)\n",
    "\n",
    "## Model 1 has a higher f1 score, which means its better at correctly identifying positive\n",
    "## cases and minimizing false positives/false negatives. Therefore, I would use model 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
