{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretical Questions\n",
    "\n",
    "Exercise 1:\n",
    "⊛ OLS is prone to overfitting in high-dimensional datasets. Also, high dimension datasets exhibit multicolinearity. \n",
    "⊛ Using regularization methods like ridge regression would be better. This is because adding regularization terms can help prevent overfitting by discouraging large coefficients. \n",
    "\n",
    "Exercise 2:\n",
    "(c) The objective function is the same as ordinary least squares objective function.\n",
    "\n",
    "Exercise 3: \n",
    "(i) (b) and (c)\n",
    "\n",
    "Exercise 4:\n",
    "High Bias. Reduce regularization parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 11879466.418280955\n",
      "Ridge Regression MSE: 12167645.251862932\n",
      "I would use Linear Regression to predict car prices because it has a lower MSE.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Exercise 5\n",
    "\n",
    "# (a)\n",
    "car_price=pd.read_csv('CarPrice_Assignment.csv')\n",
    "\n",
    "# (b)\n",
    "X=car_price[['wheelbase', 'enginesize', 'compressionratio', 'horsepower',\n",
    " 'peakrpm', 'citympg', 'highwaympg']]\n",
    "y=car_price['price']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "# (c)\n",
    "coefficients_df = pd.DataFrame(columns=X.columns)\n",
    "for _ in range(1000):\n",
    "    lasso = Lasso()\n",
    "    scaler = StandardScaler()\n",
    "    pipeline = Pipeline([('scaler', scaler), ('lasso', lasso)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    coefficients_df.loc[len(coefficients_df)] = pipeline.named_steps['lasso'].coef_\n",
    "zero_counts = (coefficients_df == 0).sum()\n",
    "variables_to_remove = zero_counts[zero_counts > 500].index.tolist()\n",
    "X_train = X_train.drop(columns=variables_to_remove)\n",
    "X_test = X_test.drop(columns=variables_to_remove)\n",
    "\n",
    "# (d)\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg_pipeline = Pipeline([('scaler', StandardScaler()), ('linear_reg', linear_reg)])\n",
    "linear_reg_pipeline.fit(X_train, y_train)\n",
    "y_pred_linear = linear_reg_pipeline.predict(X_test)\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "\n",
    "# (e)\n",
    "ridge = Ridge()\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(ridge, param_grid, cv=5)\n",
    "ridge_pipeline = Pipeline([('scaler', StandardScaler()), ('ridge', grid_search)])\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "optimal_lambdas = []\n",
    "for _ in range(100):\n",
    "    ridge_pipeline.fit(X_train, y_train)\n",
    "    optimal_lambda = ridge_pipeline.named_steps['ridge'].best_params_['alpha']\n",
    "    optimal_lambdas.append(optimal_lambda)\n",
    "most_common_lambda = np.median(optimal_lambdas)\n",
    "\n",
    "ridge = Ridge(alpha=most_common_lambda)\n",
    "ridge_pipeline = Pipeline([('scaler', StandardScaler()), ('ridge', ridge)])\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_pipeline.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "\n",
    "# (f)\n",
    "print(\"Linear Regression MSE:\", mse_linear)\n",
    "print(\"Ridge Regression MSE:\", mse_ridge)\n",
    "if mse_linear < mse_ridge:\n",
    "    print(\"I would use Linear Regression to predict car prices because it has a lower MSE.\")\n",
    "else:\n",
    "    print(\"I would use Ridge Regression to predict car prices because it has a lower MSE.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
